{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####\n",
    "In this tutorial, weâ€™ll learn how to:\n",
    "\n",
    "Read in data and with appropriate transforms (nearly identical to the prior tutorial).\n",
    "Set up TensorBoard.\n",
    "Write to TensorBoard.\n",
    "Inspect a model architecture using TensorBoard.\n",
    "Use TensorBoard to create interactive versions of the visualizations we created in last tutorial, with less code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26427392it [00:03, 7635706.23it/s]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 72899.42it/s]                            \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4423680it [00:01, 2807327.44it/s]                             \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 25022.51it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us show some of the training images, for fun.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "        _, class_preds_batch = torch.max(output, 1)\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_preds = torch.cat(class_preds)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_preds = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_preds,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
